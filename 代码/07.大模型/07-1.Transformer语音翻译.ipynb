{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad28e6a-037a-4b2d-9986-4e5f49de6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import Counter    # 计数类\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa90cc-2589-47e5-9e6d-b2fd4accf612",
   "metadata": {},
   "source": [
    "# 数据集定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6413f-7e5c-44dd-a05b-4f88b6465ed3",
   "metadata": {},
   "source": [
    "## 原始数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bcdb0-f4fc-400e-8db7-cc0d3cb2f7a3",
   "metadata": {},
   "source": [
    "### 语音数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7677fe54-d7dd-4060-9e05-d665d1785267",
   "metadata": {},
   "outputs": [],
   "source": [
    "soundmark = ['ei', 'bi:', 'si:', 'di:', 'i:',  \n",
    "             'ef', 'dʒi:', 'eit∫', 'ai', 'dʒei', \n",
    "             'kei', 'el', 'em', 'en', 'əu', \n",
    "             'pi:', 'kju:', 'ɑ:', 'es', 'ti:', \n",
    "             'ju:', 'vi:', 'd∧blju:', 'eks', 'wai', \n",
    "             'zi:']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2332538-f8b0-45c0-ba35-2b23683af93e",
   "metadata": {},
   "source": [
    "### 字母数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5917518b-051f-43a0-b079-aa607ef09b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['a', 'b', 'c', 'd', 'e',\n",
    "            'f', 'g', 'h', 'i', 'j',\n",
    "            'k', 'l', 'm', 'n', 'o',\n",
    "            'p', 'q', 'r', 's', 't',\n",
    "            'u', 'v', 'w', 'x', 'y',\n",
    "            'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617ba75-3785-496a-bfc0-3094a998ffb5",
   "metadata": {},
   "source": [
    "## 序列数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3570f2-9496-4aa8-835a-795cb6aa11ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 10000 # 序列总条数\n",
    "seq_len = 6  # 序列长度\n",
    "r = 0.9   # 扰动项\n",
    "# 原始序列（语音序列），目标序列（字母序列）\n",
    "src_tokens, tgt_tokens = [], [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed77485-99fe-450d-99a3-2552b1007766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(t):\n",
    "    src, tgt = [], []\n",
    "    for j in range(seq_len):\n",
    "        ind = random.randint(0, 25)\n",
    "        src.append(soundmark[ind])\n",
    "        if random.random() < r:\n",
    "            tgt.append(alphabet[ind])\n",
    "        else:\n",
    "            tgt.append(alphabet[random.randint(0, 25)])\n",
    "    src_tokens.append(src)\n",
    "    tgt_tokens.append(tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5a041-48d8-4901-9cc0-7f66c0865f85",
   "metadata": {},
   "source": [
    "### 语音序列数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91eb9aed-6584-4f7e-8d8b-cdea7e61a826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ɑ:', 'əu', 'kju:', 'bi:', 'di:', 'zi:'],\n",
       " ['dʒi:', 'si:', 'dʒi:', 'wai', 'eks', 'kju:'],\n",
       " ['eit∫', 'wai', 'ti:', 'dʒi:', 'ei', 'ei'],\n",
       " ['el', 'pi:', 'ef', 'kju:', 'ti:', 'si:'],\n",
       " ['es', 'zi:', 'bi:', 'en', 'ai', 'wai']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokens[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10422e2d-68a1-4556-9eb6-8cfb80e9c466",
   "metadata": {},
   "source": [
    "### 字母序列数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7687bd-7b02-4d2a-be0a-e4312d7a7851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'o', 'q', 'b', 'm', 'z'],\n",
       " ['g', 'c', 'g', 'y', 'x', 'q'],\n",
       " ['h', 'y', 't', 'g', 'a', 'n'],\n",
       " ['b', 'p', 'a', 'q', 't', 'c'],\n",
       " ['s', 'z', 'b', 'n', 'i', 'y']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_tokens[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3871d3-8013-45cb-b071-25ed236b3ad4",
   "metadata": {},
   "source": [
    "## 字典数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5708ca9-b1fe-471a-9963-747f8af8a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda li: [item for sublist in li for item in sublist]      # 展平二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a102bf-d8b8-4f4c-a7ff-269bd6700178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens  # 传入的tokens是二维列表\n",
    "        self.token2index = {'<bos>': 0, '<eos>': 1}  # 先存好特殊词元\n",
    "        # 将token按词频逆序排序后生成token到index字典\n",
    "        self.token2index.update({\n",
    "            token: index + 2\n",
    "            for index, (token, freq) in enumerate(\n",
    "                sorted(Counter(flatten(self.tokens)).items(), key=lambda x: x[1], reverse=True))\n",
    "        }) \n",
    "        # index到token字典\n",
    "        self.index2token = {index: token for token, index in self.token2index.items()}\n",
    " \n",
    "    def __getitem__(self, query):\n",
    "        # 单一索引\n",
    "        if isinstance(query, (str, int)):\n",
    "            if isinstance(query, str):\n",
    "                return self.token2index.get(query, 0)\n",
    "            elif isinstance(query, (int)):\n",
    "                return self.index2token.get(query, '<unk>')\n",
    "        # 数组索引\n",
    "        elif isinstance(query, (list, tuple)):\n",
    "            return [self.__getitem__(item) for item in query]\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.index2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde4a5c-9195-435c-aac1-ccd20c40e85c",
   "metadata": {},
   "source": [
    "### 语音字典数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b1eaa4-de1e-4671-8357-8f6dccb4f8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_vocab_size: 28\n"
     ]
    }
   ],
   "source": [
    "# 实例化语音字典数据集\n",
    "src_vocab = Vocab(src_tokens)\n",
    "# 语音字典数据集大小\n",
    "print(\"src_vocab_size: {}\".format(len(src_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c54b5-a7b7-4ec9-aeae-2ee28a2817cf",
   "metadata": {},
   "source": [
    "### 字母字典数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a96a16a-17f4-4a87-b37b-35725616a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tgt_vocab_size: 28\n"
     ]
    }
   ],
   "source": [
    "# 实例化字母字典数据集\n",
    "tgt_vocab = Vocab(tgt_tokens)\n",
    "# 字母字典数据集大小\n",
    "print(\"tgt_vocab_size: {}\".format(len(tgt_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3499d05-949e-4ad0-aaed-f61395582306",
   "metadata": {},
   "source": [
    "## 序列张量数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b4104a2-2d39-47ca-a366-f713a204881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语音序列结尾增加填充标识<pad>，并转换为语音序列张量数据集\n",
    "encoder_input = torch.tensor([src_vocab[line + ['<pad>']] for line in src_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65771e5-91cf-417b-9d85-0d0492addf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语音序列开头增加开始标识<bos>，并转换为语音序列张量数据集\n",
    "decoder_input = torch.tensor([src_vocab[['<bos>'] + line] for line in src_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb31901d-c3d0-4a05-aee7-20e855bb4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字母序列结尾增加结束标识<eos>，并转换为字母序列张量数据集\n",
    "decoder_output = torch.tensor([tgt_vocab[line + ['<eos>']] for line in tgt_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd54df5-9470-4c91-964a-86ef4e20b041",
   "metadata": {},
   "source": [
    "## 训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b000320b-f322-46d0-bf60-8666a527b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "# 训练集和测试集比例8比2\n",
    "train_size = int(len(encoder_input) * 0.8)\n",
    "test_size = len(encoder_input) - train_size\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a4f168-0c0b-41d2-83da-89eb477da5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5187f440-5118-498a-bff8-9ff7a54d69db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集函数\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, enc_input, dec_input, dec_output):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.enc_input = enc_input\n",
    "        self.dec_input = dec_input\n",
    "        self.dec_output = dec_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.enc_input.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.enc_input[idx], self.dec_input[idx], self.dec_output[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e475220c-84e5-4e1d-a30d-d553ced42576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataSet(encoder_input[:train_size], decoder_input[:train_size], decoder_output[:train_size])\n",
    "test_dataset = MyDataSet(encoder_input[-test_size:], decoder_input[-test_size:], decoder_output[-test_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "246e630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976ae9a-557e-4c08-bb60-0db13c1b1bf2",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ae716-7126-412e-a6e3-08e42b2edb4e",
   "metadata": {},
   "source": [
    "## mask没有意义(=0)的占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32265c92-ec84-4098-a573-d08c0ebe0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):  \n",
    "    # seq_q: [batch_size, len_q], seq_k: [batch_size, len_k]\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq: 比较两个tensor中，每一个对应位置上的元素是否相等。相等则对应位置置True，不等则对应位置置False\n",
    "    # 判断值为0（没有意义的占位符）的位置, 用True标记。 \n",
    "    # pad_attn_mask: [batch_size, len_k]\n",
    "    pad_attn_mask = seq_k.data.eq(0)\n",
    "    # pad_attn_mask: [batch_size, 1, len_k]\n",
    "    pad_attn_mask = pad_attn_mask.unsqueeze(1)  \n",
    "    # expand: 参数是扩展的目标，repeat: 参数是重复的次数\n",
    "    # pad_attn_mask: [batch_size, len_q, len_k]\n",
    "    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k)\n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21212f0-863f-4527-b411-7e525992d2c3",
   "metadata": {},
   "source": [
    "## mask未来信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f45380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequence_mask(seq):   \n",
    "    # seq: [batch_size, seq_len]\n",
    "    # attn_shape: [batch_size, seq_len, seq_len]\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    # 生成右上三角矩阵（不包括主对角线）：[batch_size, seq_len, seq_len]\n",
    "    # 右上三角矩阵中元素为1，其余位置元素为0\n",
    "    # subsequence_mask: [batch_size, seq_len, seq_len]\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1)  \n",
    "    # self.byte() is equivalent to self.to(torch.uint8)\n",
    "    # subsequence_mask: [batch_size, seq_len, seq_len]\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()  \n",
    "    return subsequence_mask "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad8055-d94b-4019-87fd-59e93aca0d4a",
   "metadata": {},
   "source": [
    "## 正余弦位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ad8a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_positional_encoding(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_idx) for hid_idx in range(d_model)]\n",
    "    # sinusoid_positional_encoding: [n_position, d_model]\n",
    "    sinusoid_positional_encoding = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_positional_encoding[:, 0::2] = np.sin(sinusoid_positional_encoding[:, 0::2]) # 偶数位用正弦函数\n",
    "    sinusoid_positional_encoding[:, 1::2] = np.cos(sinusoid_positional_encoding[:, 1::2]) # 奇数位用余弦函数\n",
    "    # sinusoid_positional_encoding: [n_position, d_model]\n",
    "    return torch.FloatTensor(sinusoid_positional_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74610a-6a51-4d51-bd7a-129511a1d641",
   "metadata": {},
   "source": [
    "## 缩放点积注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e7fb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, len_q, d_q]  # d_q = d_k\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v, d_v]  # len_v = len_k\n",
    "        attn_mask: [batch_size, n_heads, len_q, len_k]\n",
    "        '''\n",
    "        d_k = K.size(-1)\n",
    "        # scores: [batch_size, n_heads, len_q, len_k]\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) \n",
    "        # scores: [batch_size, n_heads, len_q, len_k]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "        # attn: [batch_size, n_heads, len_q, len_k]\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        # context: [batch_size, n_heads, len_q, d_v]\n",
    "        context = torch.matmul(attn, V) \n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e1ade7-6839-409d-a761-c9f149478a8e",
   "metadata": {},
   "source": [
    "## 多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "676a4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        # bias用于指定是否在线性变换后添加偏置项\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        '''\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v, d_model]  # len_v = len_k\n",
    "        attn_mask: [batch_size, len_q, len_k]\n",
    "        '''\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # Q: [batch_size, len_q, d_model]变为[batch_size, n_heads, len_q, d_k]\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2) \n",
    "        # K: [batch_size, len_k, d_model]变为[batch_size, n_heads, len_k, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2) \n",
    "        # V: [batch_size, len_v, d_model]变为[batch_size, n_heads, len_v, d_v]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2) \n",
    "        # expand: 参数是扩展的目标，repeat: 参数是重复的次数\n",
    "        # attn_mask : [batch_size, len_q, len_k]变为[batch_size, n_heads, len_q, len_k]\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        # context: [batch_size, n_heads, len_q, d_v]\n",
    "        # attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        # context: [batch_size, len_q, n_heads * d_v]\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, self.n_heads * self.d_v) \n",
    "        # output: [batch_size, len_q, d_model]\n",
    "        output = self.fc(context) \n",
    "        # 对应元素相加，不改变size，output: [batch_size, len_q, d_model]\n",
    "        output = output + residual\n",
    "        # 层归一化，不改变size，output: [batch_size, len_q, d_model]\n",
    "        output = nn.LayerNorm(self.d_model)(output)\n",
    "        # output: [batch_size, len_q, d_model]，attn: [batch_size, n_heads, len_q, len_k]\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e3414-4699-473e-b5f1-9262e9c07657",
   "metadata": {},
   "source": [
    "## 前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b68eb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):    \n",
    "        # input: [batch_size, seq_len, d_model]\n",
    "        residual = input\n",
    "        # output: [batch_size, seq_len, d_model]\n",
    "        output = self.fc(input)\n",
    "        # 残差 + LayerNorm\n",
    "        # output: [batch_size, seq_len, d_model]\n",
    "        output = nn.LayerNorm(self.d_model)(output + residual)   \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59ca10-84e3-45ba-84c6-1315b3409bdb",
   "metadata": {},
   "source": [
    "## 编码器层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f10f6d79-b516-4529-af23-b063b4f50c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, d_v):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, d_v)  # 多头注意力\n",
    "        self.ffn = FeedForwardNet(d_model, d_ff)  # 前馈网络\n",
    "    def forward(self, enc_input, enc_self_attn_mask):\n",
    "        '''\n",
    "        enc_input: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        '''\n",
    "        # enc_input to same Q, K, V\n",
    "        # enc_output: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        enc_output, attn = self.enc_self_attn(enc_input, enc_input, enc_input, enc_self_attn_mask) \n",
    "        # enc_output: [batch_size, src_len, d_model]\n",
    "        enc_output = self.ffn(enc_output) \n",
    "        # enc_output: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        return enc_output, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de45b0-890e-4868-8731-052ce45df6b2",
   "metadata": {},
   "source": [
    "## 编码器模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eae1e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, src_vocab_size, d_model, d_ff, d_k, d_v):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_positional_encoding(src_vocab_size, d_model), freeze=True)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, d_v) for _ in range(n_layers)])\n",
    "    def forward(self, enc_input):\n",
    "        '''\n",
    "        enc_input: [batch_size, src_len]\n",
    "        '''\n",
    "        # word_emb: [batch_size, src_len, d_model]\n",
    "        word_emb = self.src_emb(enc_input) \n",
    "        # pos_emb: [batch_size, src_len, d_model]\n",
    "        pos_emb = self.pos_emb(enc_input) \n",
    "        # enc_output: [batch_size, src_len, d_model]\n",
    "        enc_output = word_emb + pos_emb\n",
    "        # enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_input, enc_input) \n",
    "        enc_output_list = []\n",
    "        enc_self_attn_list = []\n",
    "        for layer in self.layers:\n",
    "            # enc_output: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n",
    "            enc_output, enc_self_attn = layer(enc_output, enc_self_attn_mask)\n",
    "            enc_output_list.append(enc_output)\n",
    "            enc_self_attn_list.append(enc_self_attn)\n",
    "        # enc_output_list: [n_layers, batch_size, src_len, d_model]\n",
    "        # enc_self_attn_list: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        return enc_output_list, enc_self_attn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18da099-27f5-46ae-931d-158aaf73071b",
   "metadata": {},
   "source": [
    "## 解码器层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1b220e6-afce-492d-87c9-32f0bd96848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, d_v):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(n_heads, d_model, d_k, d_v)\n",
    "        self.dec_enc_attn = MultiHeadAttention(n_heads, d_model, d_k, d_v)\n",
    "        self.ffn = FeedForwardNet(d_model, d_ff)\n",
    "    def forward(self, dec_input, enc_output, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        '''\n",
    "        dec_input: [batch_size, tgt_len, d_model]\n",
    "        enc_output: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        '''       \n",
    "        # dec_output: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_output, dec_self_attn = self.dec_self_attn(dec_input, dec_input, dec_input, dec_self_attn_mask)\n",
    "        # dec_output: [batch_size, tgt_len, d_model], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "        dec_output, dec_enc_attn = self.dec_enc_attn(dec_output, enc_output, enc_output, dec_enc_attn_mask)\n",
    "        # dec_output: [batch_size, tgt_len, d_model]\n",
    "        dec_output = self.ffn(dec_output) \n",
    "        # dec_output: [batch_size, tgt_len, d_model]\n",
    "        # dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        # dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "        return dec_output, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b9d8f-0744-4417-94ed-0ed223f4cb73",
   "metadata": {},
   "source": [
    "## 解码器模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "416d9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, tgt_vocab_size, d_model, d_ff, d_k, d_v):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_positional_encoding(tgt_vocab_size, d_model), freeze=True)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(n_heads, d_model, d_ff, d_k, d_v) for _ in range(n_layers)])\n",
    "    def forward(self, dec_input, enc_input, enc_output_list):\n",
    "        '''\n",
    "        dec_input: [batch_size, tgt_len]\n",
    "        enc_input: [batch_size, src_len]\n",
    "        enc_output: [batsh_size, src_len, d_model]\n",
    "        '''\n",
    "        # word_emb: [batch_size, tgt_len, d_model]\n",
    "        word_emb = self.tgt_emb(dec_input) \n",
    "        # pos_emb: [batch_size, tgt_len, d_model]\n",
    "        pos_emb = self.pos_emb(dec_input) \n",
    "        # dec_output: [batch_size, tgt_len, d_model]\n",
    "        dec_output = word_emb + pos_emb\n",
    "        # dec_self_attn_pad_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_input, dec_input) \n",
    "        # dec_self_attn_subsequent_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequence_mask(dec_input) \n",
    "        # dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0) \n",
    "        # dec_enc_attn_mask: [batc_size, tgt_len, src_len]\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_input, enc_input) \n",
    "        dec_self_attn_list, dec_enc_attn_list = [], []\n",
    "        for i in range(len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            enc_output = enc_output_list[i]\n",
    "            # dec_output: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "            dec_output, dec_self_attn, dec_enc_attn = layer(dec_output, enc_output, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attn_list.append(dec_self_attn)\n",
    "            dec_enc_attn_list.append(dec_enc_attn)\n",
    "        # dec_output: [batch_size, tgt_len, d_model], dec_self_attn: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, h_heads, tgt_len, src_len]\n",
    "        return dec_output, dec_self_attn_list, dec_enc_attn_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca4e83a-52a6-4044-8e36-b1a18ff759a2",
   "metadata": {},
   "source": [
    "## Transformer类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5461ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, src_vocab_size, tgt_vocab_size, d_model, d_ff, d_k, d_v):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(n_layers, n_heads, src_vocab_size, d_model, d_ff, d_k, d_v)\n",
    "        self.decoder = Decoder(n_layers, n_heads, tgt_vocab_size, d_model, d_ff, d_k, d_v)\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False)\n",
    "    def forward(self, enc_input, dec_input):\n",
    "        '''\n",
    "        enc_input: [batch_size, src_len]\n",
    "        dec_input: [batch_size, tgt_len]\n",
    "        '''\n",
    "        # enc_output_list: [n_layers, batch_size, src_len, d_model]\n",
    "        # enc_self_attn_list: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        enc_output_list, enc_self_attn_list = self.encoder(enc_input)\n",
    "        # dec_output: [batch_size, tgt_len, d_model], dec_self_attn_list: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn_list: [n_layers, batch_size, h_heads, tgt_len, src_len]\n",
    "        dec_output, dec_self_attn_list, dec_enc_attn_list = self.decoder(dec_input, enc_input, enc_output_list)\n",
    "        # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "        dec_logits = self.projection(dec_output) \n",
    "        # dec_logits: [batch_size * tgt_len, tgt_vocab_size]\n",
    "        dec_logits = dec_logits.view(-1, dec_logits.size(-1))\n",
    "        # dec_logits: [batch_size * tgt_len, tgt_vocab_size]\n",
    "        # enc_self_attn_list: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        # dec_self_attn_list: [n_layers, batch_size, n_heads, tgt_len, tgt_len]\n",
    "        # dec_enc_attn_list: [n_layers, batch_size, h_heads, tgt_len, src_len]\n",
    "        return dec_logits, enc_self_attn_list, dec_self_attn_list, dec_enc_attn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcac0d8e-7e57-4226-b2bb-54fc617a4927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_layers: 有多少个encoder和decoder\n",
    "# n_heads: Multi-Head Self Attention设置为8\n",
    "# d_model: Embedding的维度\n",
    "# d_ff: 前馈网络隐藏层维度\n",
    "# d_k: K(=Q)的维度 \n",
    "# d_v: V的维度 \n",
    "model = Transformer(n_layers=6, n_heads=8, d_model=512, d_ff=2048, d_k=64, d_v=64, src_vocab_size=len(src_vocab), tgt_vocab_size=len(tgt_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0a7e0-3269-4799-85bf-1b07f2f80e7a",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fae933c9-ff8b-455d-b795-52f657a25888",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.99)\n",
    "# num_epochs = 50 # 训练50轮\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f2cf469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [04:13<04:13, 253.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss = 2.103910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [07:43<00:00, 231.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 loss = 1.488285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 记录损失变化\n",
    "loss_history = []\n",
    "model.train()\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    total_loss = 0\n",
    "    for enc_input, dec_input, dec_output in train_loader:\n",
    "        '''\n",
    "        enc_input: [batch_size, src_len]\n",
    "        dec_input: [batch_size, tgt_len]\n",
    "        dec_output: [batch_size, tgt_len]\n",
    "        '''\n",
    "        # enc_input, dec_input, dec_output = enc_input.to(device), dec_input.to(device), dec_output.to(device)\n",
    "        # output: [batch_size * tgt_len, tgt_vocab_size]\n",
    "        # enc_self_attn_list: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        # dec_self_attn_list: [n_layers, batch_size, n_heads, tgt_len, tgt_len]\n",
    "        # dec_enc_attn_list: [n_layers, batch_size, h_heads, tgt_len, src_len]\n",
    "        output, enc_self_attn_list, dec_self_attn_list, dec_enc_attn_list = model(enc_input, dec_input)\n",
    "        loss = criterion(output, dec_output.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    print('Epoch:', '%d' % (epoch + 1), 'loss =', '{:.6f}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c7f102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.ylabel('train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240691bf-630c-4e56-b8d5-d173bcc3fe50",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c99ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_results = []\n",
    "correct = 0\n",
    "error = 0\n",
    "model.eval()\n",
    "for enc_input, dec_input, dec_output in test_loader:\n",
    "    '''\n",
    "    enc_input: [batch_size=1, src_len]\n",
    "    dec_input: [batch_size=1, tgt_len]\n",
    "    dec_output: [batch_size=1, tgt_len]\n",
    "    '''\n",
    "    # enc_input, dec_input, dec_output = enc_input.to(device), dec_input.to(device), dec_output.to(device)\n",
    "    # output: [batch_size * tgt_len, tgt_vocab_size]，即[tgt_len, tgt_vocab_size]\n",
    "    output, enc_self_attn, dec_self_attn, dec_enc_attn = model(enc_input, dec_input)\n",
    "    # squeeze(): 移除所有大小为1的维度\n",
    "    # output: [tgt_len, tgt_vocab_size]\n",
    "    output = output.squeeze()\n",
    "    pred_seq = []\n",
    "    for out in output:\n",
    "        next_token_index = out.argmax().item()\n",
    "        if next_token_index == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        pred_seq.append(next_token_index)\n",
    "    pred_seq = tgt_vocab[pred_seq]\n",
    "\n",
    "    src_seq = enc_input.squeeze().tolist()  \n",
    "    # 需要注意在<pad>之前截断\n",
    "    if src_vocab['<pad>'] in src_seq:\n",
    "        eos_idx = src_seq.index(src_vocab['<pad>'])\n",
    "        src_seq = src_vocab[src_seq[:eos_idx]]\n",
    "    else:\n",
    "        src_seq = src_vocab[src_seq]\n",
    "    \n",
    "    tgt_seq = dec_output.squeeze().tolist()  \n",
    "    # 需要注意在<eos>之前截断\n",
    "    if tgt_vocab['<eos>'] in tgt_seq:\n",
    "        eos_idx = tgt_seq.index(tgt_vocab['<eos>'])\n",
    "        tgt_seq = tgt_vocab[tgt_seq[:eos_idx]]\n",
    "    else:\n",
    "        tgt_seq = tgt_vocab[tgt_seq]\n",
    "        \n",
    "    translation_results.append(('输入：' + ' '.join(src_seq), '输出：' + ' '.join(tgt_seq), '预测：' + ' '.join(pred_seq)))\n",
    "    for i in range(len(tgt_seq)):\n",
    "        if i >= len(pred_seq) or pred_seq[i] != tgt_seq[i]:\n",
    "            error += 1\n",
    "        else:\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ff62b4d-2492-40f4-8fe2-e30e607f9726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 5991, error: 6009, correct_ratio: 0.49925\n"
     ]
    }
   ],
   "source": [
    "print(\"correct: {}, error: {}, correct_ratio: {}\".format(correct, error, correct / (correct + error)))\n",
    "# correct: 5991, error: 6009, correct_ratio: 0.49925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87a19f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('输入：d∧blju: es di: ju: bi: es', '输出：w s d u y p', '预测：w b b b b'),\n",
       " ('输入：ti: si: d∧blju: d∧blju: zi: el', '输出：t c w w z l', '预测：t w w z l l'),\n",
       " ('输入：en vi: i: ai vi: vi:', '输出：n v e i v k', '预测：i v i v v'),\n",
       " ('输入：kju: əu en bi: em vi:', '输出：q w n b m v', '预测：q v b b m'),\n",
       " ('输入：vi: en kei kju: pi: ei', '输出：z n k q p a', '预测：v a a a a a'),\n",
       " ('输入：zi: ɑ: kei eks ai bi:', '输出：z r k x i g', '预测：z b b b b b'),\n",
       " ('输入：kei em wai vi: bi: zi:', '输出：k m y v b z', '预测：k z b b z z'),\n",
       " ('输入：en vi: ti: vi: kei bi:', '输出：n v t v k b', '预测：n v k k k b'),\n",
       " ('输入：bi: kei eks wai kju: es', '输出：b k x y q s', '预测：b q x q q'),\n",
       " ('输入：ti: zi: vi: el əu dʒi:', '输出：t z v l o g', '预测：t o o o g g')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_results[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd7641-ebc2-4c1a-8739-a83302f37b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
