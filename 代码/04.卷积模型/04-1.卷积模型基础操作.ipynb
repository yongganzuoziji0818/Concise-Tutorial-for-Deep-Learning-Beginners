{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5075f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbf37a-5126-4402-a805-ea9ebd0e350e",
   "metadata": {},
   "source": [
    "# 卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970d223-0787-488a-af02-5871779c0363",
   "metadata": {},
   "source": [
    "## 二维卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f1946-720a-4357-90d4-40e41e13d33e",
   "metadata": {},
   "source": [
    "### 二维卷积层(nn.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5904d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f1aef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 26, 26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=0)\n",
    "out = layer.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96cf4414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1)\n",
    "out = layer.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d34e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 14, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Conv2d(1, 3, kernel_size=3, stride=2, padding=1)\n",
    "out = layer.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "829d6b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 14, 14])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82e8bf5-9eef-432b-95d5-b3407bc0ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.2644,  0.2847,  0.2930],\n",
       "          [ 0.1113,  0.2629, -0.3034],\n",
       "          [ 0.1228,  0.1768,  0.1741]]],\n",
       "\n",
       "\n",
       "        [[[-0.1835,  0.2314, -0.1864],\n",
       "          [ 0.1513,  0.1873, -0.1763],\n",
       "          [ 0.1927, -0.0050, -0.1213]]],\n",
       "\n",
       "\n",
       "        [[[-0.1334,  0.2806,  0.2717],\n",
       "          [-0.0815,  0.1575, -0.1269],\n",
       "          [-0.0161,  0.1885, -0.1310]]]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 权重\n",
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2afbafc-80ac-4926-914e-298deb22ff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2439,  0.2684,  0.2459], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 偏差\n",
    "layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8008a94-20e7-4e8d-9814-ad32a89ede4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估\n",
    "layer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0b8189d-2d4a-47f2-a300-929dcea3f34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': {'weight': Parameter containing:\n",
       "  tensor([[[[-0.2644,  0.2847,  0.2930],\n",
       "            [ 0.1113,  0.2629, -0.3034],\n",
       "            [ 0.1228,  0.1768,  0.1741]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1835,  0.2314, -0.1864],\n",
       "            [ 0.1513,  0.1873, -0.1763],\n",
       "            [ 0.1927, -0.0050, -0.1213]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.1334,  0.2806,  0.2717],\n",
       "            [-0.0815,  0.1575, -0.1269],\n",
       "            [-0.0161,  0.1885, -0.1310]]]], requires_grad=True),\n",
       "  'bias': Parameter containing:\n",
       "  tensor([-0.2439,  0.2684,  0.2459], requires_grad=True)},\n",
       " '_buffers': {},\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': {},\n",
       " 'in_channels': 1,\n",
       " 'out_channels': 3,\n",
       " 'kernel_size': (3, 3),\n",
       " 'stride': (2, 2),\n",
       " 'padding': (1, 1),\n",
       " 'dilation': (1, 1),\n",
       " 'transposed': False,\n",
       " 'output_padding': (0, 0),\n",
       " 'groups': 1,\n",
       " 'padding_mode': 'zeros',\n",
       " '_reversed_padding_repeated_twice': (1, 1, 1, 1)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vars返回对象的属性和属性值的字典对象\n",
    "vars(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8488b-1da4-4c65-8a1d-76af86c5793b",
   "metadata": {},
   "source": [
    "### 二维卷积操作(F.Conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76b942b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(16, 3, 5, 5)\n",
    "b = torch.randn(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83f47019",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 5, 5], expected input[1, 1, 28, 28] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 以下语句会报错，x通道数不为3\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 5, 5], expected input[1, 1, 28, 28] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "# 以下语句会报错，因为x通道数不为3\n",
    "out = F.conv2d(x, w, b, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5582e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96bd7f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 26, 26])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.conv2d(x, w, b, stride=1, padding=1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a89d1942",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 14, 14])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.conv2d(x, w, b, stride=2, padding=2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1193151-6d79-41db-85a8-6bb72d284493",
   "metadata": {},
   "source": [
    "## 一维卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550ae1a-e2cf-40c9-9dea-b200f2d9f0dd",
   "metadata": {},
   "source": [
    "### 一维卷积层(nn.Conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2e51321-cae0-4dd9-bb1d-d76a95687d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入张量，形状为(batch_size=1, in_channels=1, sequence_length=10)\n",
    "x = torch.randn(1, 1, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "884a64c7-f5c0-4a38-a3fa-c68a8f3c38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Conv1d(in_channels=1, out_channels=10, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6b8d5a4-1361-413e-93ae-dd6f57ce8096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = layer(x)\n",
    "output.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe27c6-52a6-4712-8641-d19b2639ebac",
   "metadata": {},
   "source": [
    "### 一维卷积操作(F.conv1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db0f3e7b-3d65-4165-a3d6-3cb996c55cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积权重，形状为(out_channels=10, in_channels=1, kernel_size=3)\n",
    "w = torch.randn(10, 1, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e170ac21-7458-409f-bfd8-7c4d779f1a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = F.conv1d(x, w)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76245a",
   "metadata": {},
   "source": [
    "# 池化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cae76-1222-4ed3-9376-a7180a8034d1",
   "metadata": {},
   "source": [
    "## 最大池化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572b471-330b-49d4-9292-b0800ccd254d",
   "metadata": {},
   "source": [
    "### 最大池化层(nn.MaxPool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed023124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 14, 14])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = out\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f527b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.MaxPool2d(2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07831291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc69dd-fa43-4ff0-812a-c0b9e55b7dae",
   "metadata": {},
   "source": [
    "### 最大池化操作(F.max_pool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecebc11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.max_pool2d(x, 2, stride=2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94ba93-45ff-4729-87e3-2e709af17478",
   "metadata": {},
   "source": [
    "## 平均池化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a658ab0-3fdb-4114-880a-cb4a71157f2d",
   "metadata": {},
   "source": [
    "### 平均池化层(nn.AvgPool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8dc0376-bc8a-4a7e-9eaa-b057c767677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.AvgPool2d(2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7cdba38-6063-495f-9ce4-167025e5150d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223aa19-1918-48a7-9933-c7bae0469496",
   "metadata": {},
   "source": [
    "### 平均池化操作(F.avg_pool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bde42171-fffc-4851-98a3-7d027fa13fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = F.avg_pool2d(x, 2, stride=2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db889bd6-c4ea-4e7b-bbdc-826ccbeeed93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.727px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
