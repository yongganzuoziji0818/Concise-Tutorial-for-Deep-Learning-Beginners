{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ab86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg19\n",
    "from PIL import Image\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ea90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储模型的目录\n",
    "os.environ['TORCH_HOME'] = './model'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc0986",
   "metadata": {},
   "source": [
    "# 加载图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4021d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, max_size=400):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    # 如果图片过大则调整大小\n",
    "    size = min(max_size, max(image.size))\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # 添加批次维度\n",
    "    image = transform(image).unsqueeze(0)  \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82a60e",
   "metadata": {},
   "source": [
    "# 保存图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd09b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(tensor, path):\n",
    "    # 取消归一化并返回结果\n",
    "    unnormalize = transforms.Normalize(\n",
    "        mean=[-2.118, -2.036, -1.804],\n",
    "        std=[4.367, 4.464, 4.444]\n",
    "    )\n",
    "    tensor = unnormalize(tensor)\n",
    "    image = tensor.clone().detach()\n",
    "    # 去掉批次维度\n",
    "    image = image.squeeze(0)  \n",
    "    image = transforms.ToPILImage()(image)\n",
    "    image.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78577e89",
   "metadata": {},
   "source": [
    "# 定义特征提取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5dd7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义VGG19模型，只提取特定层的特征\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        # 只使用前21层\n",
    "        self.features = vgg19(pretrained=True).features[:21].eval()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i, layer in enumerate(self.features):\n",
    "            x = layer(x)\n",
    "            # 选择特定层的输出\n",
    "            if i in {0, 5, 10, 19, 21}:  \n",
    "                features.append(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc937c",
   "metadata": {},
   "source": [
    "# 计算内容损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae43a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input：输入，target：目标\n",
    "        # 输入和目标的内容误差\n",
    "        return nn.functional.mse_loss(input, self.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6e68c",
   "metadata": {},
   "source": [
    "# 计算风格损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8904ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    batch_size, channels, height, width = input.size()\n",
    "    features = input.view(batch_size * channels, height * width)\n",
    "    G = torch.mm(features, features.t())\n",
    "    return G.div(batch_size * channels * height * width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7914da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        # 目标的风格\n",
    "        self.target = gram_matrix(target).detach()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 输入的风格\n",
    "        G = gram_matrix(input)\n",
    "        # 输入和目标的风格误差\n",
    "        return nn.functional.mse_loss(G, self.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae46551",
   "metadata": {},
   "source": [
    "# 图像风格迁移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d024d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer(content_img, style_img, num_steps=1000, style_weight=1e9, content_weight=1):\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    content_img = content_img.to(device)\n",
    "    style_img = style_img.to(device)\n",
    "    model = VGG().to(device)\n",
    "    # 提取风格特征和内容特征\n",
    "    style_features = model(style_img)\n",
    "    content_features = model(content_img)\n",
    "    # 初始化输入图像（使用内容图像作为初始图像）\n",
    "    input_img = content_img.clone().requires_grad_(True).to(device)\n",
    "    # 定义优化器\n",
    "    optimizer = optim.LBFGS([input_img])\n",
    "    style_losses = []\n",
    "    content_losses = []\n",
    "    # 初始化损失模块\n",
    "    for sf, cf in zip(style_features, content_features):\n",
    "        content_losses.append(ContentLoss(cf))\n",
    "        style_losses.append(StyleLoss(sf))\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            input_features = model(input_img)\n",
    "            content_loss = 0\n",
    "            style_loss = 0\n",
    "            # 累加内容损失\n",
    "            for cl, input_f in zip(content_losses, input_features):\n",
    "                content_loss += content_weight * cl(input_f)\n",
    "            # 累加风格损失\n",
    "            for sl, input_f in zip(style_losses, input_features):\n",
    "                style_loss += style_weight * sl(input_f)\n",
    "            loss = content_loss + style_loss\n",
    "            loss.backward()\n",
    "            run[0] += 1\n",
    "            if run[0] % 50 == 0:\n",
    "                print(f'Step {run[0]}, Content Loss: {content_loss.item():4f}, Style Loss: {style_loss.item():4f}')\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44187cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if __name__ == '__main__':\n",
    "        content_image_path = 'image/content_image.png'\n",
    "        style_image_path = 'image/style_image.png'\n",
    "        output_image_path = 'image/output_image.jpg'\n",
    "    \n",
    "        content_img = load_image(content_image_path)\n",
    "        style_img = load_image(style_image_path)\n",
    "        result = style_transfer(content_img, style_img)\n",
    "    \n",
    "        save_image(result, output_image_path)\n",
    "        print(f\"风格迁移完成，图像已保存为 {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1ed1ff-726a-4450-a182-06238b9b7e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\DL_Basic\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\ProgramData\\Anaconda3\\envs\\DL_Basic\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50, Content Loss: 29.754610, Style Loss: 2030.043701\n",
      "Step 100, Content Loss: 30.590519, Style Loss: 700.369385\n",
      "Step 150, Content Loss: 31.174225, Style Loss: 365.433228\n",
      "Step 200, Content Loss: 31.571880, Style Loss: 250.382965\n",
      "Step 250, Content Loss: 31.778713, Style Loss: 197.025391\n",
      "Step 300, Content Loss: 31.942102, Style Loss: 163.526123\n",
      "Step 350, Content Loss: 32.088745, Style Loss: 142.871002\n",
      "Step 400, Content Loss: 32.167210, Style Loss: 128.662079\n",
      "Step 450, Content Loss: 32.240772, Style Loss: 118.532410\n",
      "Step 500, Content Loss: 32.298084, Style Loss: 110.577751\n",
      "Step 550, Content Loss: 32.349014, Style Loss: 104.269287\n",
      "Step 600, Content Loss: 32.393829, Style Loss: 99.337952\n",
      "Step 650, Content Loss: 32.429863, Style Loss: 95.298645\n",
      "Step 700, Content Loss: 32.460632, Style Loss: 92.166992\n",
      "Step 750, Content Loss: 32.481163, Style Loss: 89.454445\n",
      "Step 800, Content Loss: 32.517361, Style Loss: 87.031052\n",
      "Step 850, Content Loss: 32.539078, Style Loss: 84.895279\n",
      "Step 900, Content Loss: 32.560188, Style Loss: 83.117752\n",
      "Step 950, Content Loss: 32.582108, Style Loss: 81.530624\n",
      "Step 1000, Content Loss: 32.597988, Style Loss: 80.158600\n",
      "风格迁移完成，图像已保存为 image/output_image.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fd71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
