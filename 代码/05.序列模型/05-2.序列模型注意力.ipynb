{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fab6fafc-8b8d-42f1-a786-f33805fb1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "import matplotlib.pyplot as plt  \n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8589b23-6dee-4d40-ac68-7f7a2f2aa822",
   "metadata": {},
   "source": [
    "# 自注意力分步骤实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd91547-4541-4937-8514-a35a58e87d49",
   "metadata": {},
   "source": [
    "## 输入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2f51f13-bb08-4e32-aeb1-b5fa9d6fd0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 2, seq_len = 3, d_k = 4\n",
    "x = [\n",
    "    [[1, 0, 1, 0], \n",
    "     [0, 2, 0, 2], \n",
    "     [1, 1, 1, 1]],\n",
    "    [[2, 0, 2, 0], \n",
    "     [0, 1, 0, 1], \n",
    "     [1, 2, 1, 2]]\n",
    "]\n",
    "x = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab145c-1cc3-4e75-ab92-f54f4168d327",
   "metadata": {},
   "source": [
    "## 权重矩阵（随机初始化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bcdc042-8065-496e-b14e-f0266447e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "d_k = 4\n",
    "w_k = torch.randn(d_k, d_k, dtype=torch.float32)\n",
    "w_q = torch.randn(d_k, d_k, dtype=torch.float32)\n",
    "w_v = torch.randn(d_k, d_k, dtype=torch.float32)\n",
    "print(d_k ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11007f87-2328-42ed-aac1-251ed0fad127",
   "metadata": {},
   "source": [
    "## 计算Q, K和V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf77e70f-ae1b-49b9-8035-d19d4edfb965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.6102,  0.7005, -0.5583, -1.4088],\n",
      "         [-2.6734,  3.2910, -1.7739,  4.6357],\n",
      "         [ 0.2735,  2.3459, -1.4452,  0.9091]],\n",
      "\n",
      "        [[ 3.2203,  1.4009, -1.1165, -2.8175],\n",
      "         [-1.3367,  1.6455, -0.8870,  2.3179],\n",
      "         [-1.0632,  3.9914, -2.3322,  3.2270]]])\n",
      "tensor([[[-0.3881, -0.8802, -1.7169, -0.9112],\n",
      "         [ 0.9074, -2.3962, -2.9904, -2.2324],\n",
      "         [ 0.0656, -2.0783, -3.2121, -2.0274]],\n",
      "\n",
      "        [[-0.7762, -1.7603, -3.4338, -1.8224],\n",
      "         [ 0.4537, -1.1981, -1.4952, -1.1162],\n",
      "         [ 0.5193, -3.2763, -4.7073, -3.1437]]])\n",
      "tensor([[[ 5.9471e-01, -5.0952e-01, -3.0954e-01, -6.5931e-03],\n",
      "         [-7.9302e-01, -1.1259e-01, -7.2944e-04,  1.0061e+00],\n",
      "         [ 1.9820e-01, -5.6581e-01, -3.0991e-01,  4.9644e-01]],\n",
      "\n",
      "        [[ 1.1894e+00, -1.0190e+00, -6.1908e-01, -1.3186e-02],\n",
      "         [-3.9651e-01, -5.6296e-02, -3.6472e-04,  5.0303e-01],\n",
      "         [-1.9831e-01, -6.2211e-01, -3.1027e-01,  9.9947e-01]]])\n"
     ]
    }
   ],
   "source": [
    "q = x @ w_q\n",
    "k = x @ w_k\n",
    "v = x @ w_v\n",
    "print(q)\n",
    "print(k)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad4c23-0521-4885-8e56-eb5d118e2cfa",
   "metadata": {},
   "source": [
    "## 计算注意力分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebc86a81-3439-4220-8223-1a87a75c96d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5004,  2.2985,  1.6496],\n",
       "         [-1.5188, -7.6779, -5.3577],\n",
       "         [-0.2590, -1.5404, -1.0292]],\n",
       "\n",
       "        [[ 2.0015,  2.2985,  5.5977],\n",
       "         [-1.5188, -1.9195, -4.5983],\n",
       "         [-2.0368, -2.6897, -6.3978]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores = torch.bmm(q, k.transpose(1, 2)) / (d_k ** 0.5)\n",
    "attn_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c781fa-43c4-4a27-a0c5-6600c91f4f8d",
   "metadata": {},
   "source": [
    "## 计算注意力权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04cd3dd0-fed4-4dc6-bde1-c129cd2022c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0981, 0.5923, 0.3096],\n",
       "         [0.9769, 0.0021, 0.0210],\n",
       "         [0.5745, 0.1595, 0.2660]],\n",
       "\n",
       "        [[0.0258, 0.0347, 0.9396],\n",
       "         [0.5828, 0.3904, 0.0268],\n",
       "         [0.6522, 0.3395, 0.0083]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights = softmax(attn_scores, dim=-1)\n",
    "attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22a784-aa29-4fe7-b9b4-5e5552161f28",
   "metadata": {},
   "source": [
    "## 计算注意力输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69262afa-6a78-4458-be01-6bd919d2604f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3500, -0.2918, -0.1267,  0.7490],\n",
       "         [ 0.5835, -0.5099, -0.3089,  0.0061],\n",
       "         [ 0.2679, -0.4612, -0.2604,  0.2887]],\n",
       "\n",
       "        [[-0.1694, -0.6127, -0.3075,  0.9562],\n",
       "         [ 0.5331, -0.6325, -0.3693,  0.2155],\n",
       "         [ 0.6395, -0.6889, -0.4065,  0.1705]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = attn_weights @ v\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31362c-069d-48e0-9a6a-159f870e7e48",
   "metadata": {},
   "source": [
    "# 自注意力类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33aa8688-e51c-4c8c-814f-ea30718e31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):  \n",
    "    def __init__(self, d_k):  \n",
    "        super().__init__()  \n",
    "        self.d_k = d_k\n",
    "        self.w_q = nn.Linear(self.d_k, self.d_k)  \n",
    "        self.w_k = nn.Linear(self.d_k, self.d_k)  \n",
    "        self.w_v = nn.Linear(self.d_k, self.d_k)  \n",
    " \n",
    "    def forward(self, x):  \n",
    "        # x: (batch_size, seq_len, d_k) \n",
    "        q = self.w_q(x)  # (batch_size, seq_len, d_k)  \n",
    "        k = self.w_k(x) # (batch_size, seq_len, d_k)  \n",
    "        v = self.w_v(x) # (batch_size, seq_len, d_k)  \n",
    "        attn_scores = torch.bmm(q, k.transpose(1, 2))  # (batch_size, seq_len, seq_len)  \n",
    "        attn_scores = attn_scores / k.size(-1) ** 0.5  # 缩放  # (batch_size, seq_len, seq_len) \n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (batch_size, seq_len, seq_len) \n",
    "        output = attn_weights @ v  # (batch_size, seq_len, dim)  \n",
    "        return output, attn_weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7f1ea67-07bf-4674-821a-a04ed1547a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5798, -0.0193, -0.4038,  0.2496],\n",
       "          [ 0.5773,  0.0346, -0.3360,  0.4236],\n",
       "          [ 0.5802,  0.0058, -0.3736,  0.3312]],\n",
       " \n",
       "         [[ 0.9531, -0.1236, -0.8406,  0.0476],\n",
       "          [ 0.7357, -0.0441, -0.5633,  0.2262],\n",
       "          [ 0.6592, -0.0076, -0.4553,  0.3167]]], grad_fn=<UnsafeViewBackward0>),\n",
       " tensor([[[0.3002, 0.3288, 0.3710],\n",
       "          [0.2624, 0.4786, 0.2590],\n",
       "          [0.2799, 0.3976, 0.3225]],\n",
       " \n",
       "         [[0.3833, 0.1928, 0.4239],\n",
       "          [0.2455, 0.4091, 0.3454],\n",
       "          [0.1792, 0.4908, 0.3300]]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention = SelfAttention(4)\n",
    "self_attention(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8d900-ea52-4656-9ab1-65df04eeb7e2",
   "metadata": {},
   "source": [
    "# 注意力类（带掩码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ca5e0e4-6b7b-40fe-9c92-c62dc587479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        '''\n",
    "        Q: [batch_size, n_heads, len_q, d_q]  d_q = d_k\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v, d_v]  # len_v = len_k\n",
    "        attn_mask: [batch_size, n_heads, len_q, len_k]\n",
    "        '''\n",
    "        d_k = K.size(-1)\n",
    "        # scores: [batch_size, n_heads, len_q, len_k]\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) \n",
    "        if attn_mask is not None:  \n",
    "            # scores: [batch_size, n_heads, len_q, len_k]\n",
    "            scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n",
    "        # attn: [batch_size, n_heads, len_q, len_k]\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        # context: [batch_size, n_heads, len_q, d_v]\n",
    "        context = torch.matmul(attn, V) \n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f217b27-a72e-4599-81ba-814184def8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3500, -0.2918, -0.1267,  0.7490],\n",
       "          [ 0.5835, -0.5099, -0.3089,  0.0061],\n",
       "          [ 0.2679, -0.4612, -0.2604,  0.2887]],\n",
       " \n",
       "         [[-0.1694, -0.6127, -0.3075,  0.9562],\n",
       "          [ 0.5331, -0.6325, -0.3693,  0.2155],\n",
       "          [ 0.6395, -0.6889, -0.4065,  0.1705]]]),\n",
       " tensor([[[0.0981, 0.5923, 0.3096],\n",
       "          [0.9769, 0.0021, 0.0210],\n",
       "          [0.5745, 0.1595, 0.2660]],\n",
       " \n",
       "         [[0.0258, 0.0347, 0.9396],\n",
       "          [0.5828, 0.3904, 0.0268],\n",
       "          [0.6522, 0.3395, 0.0083]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Attention()\n",
    "attention(q, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4926b6-d47b-4de9-a592-674fc8f8685f",
   "metadata": {},
   "source": [
    "# 多头注意力类（带掩码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80cd6b70-7512-47c2-b7f4-9c821aae111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):  \n",
    "    def __init__(self, d_model, num_heads):  \n",
    "        super().__init__()  \n",
    "        self.d_model = d_model  \n",
    "        self.num_heads = num_heads  \n",
    "        self.d_k = d_model // num_heads  \n",
    " \n",
    "        self.w_q = nn.Linear(d_model, d_model)  \n",
    "        self.w_k = nn.Linear(d_model, d_model)  \n",
    "        self.w_v = nn.Linear(d_model, d_model)  \n",
    "        self.w_o = nn.Linear(d_model, d_model)  \n",
    " \n",
    "    def split_heads(self, x):  \n",
    "        # x: (batch_size, seq_len, d_model)  \n",
    "        # (batch_size, self.num_heads, seq_len, self.d_k)\n",
    "        return x.view(x.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)    \n",
    " \n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask=None):  \n",
    "        # (batch_size, self.num_heads, seq_len_q, self.d_k)  \n",
    "        q = self.split_heads(self.w_q(input_Q))  \n",
    "        # (batch_size, self.num_heads, seq_len_k, self.d_k)  \n",
    "        k = self.split_heads(self.w_k(input_K))  \n",
    "        # (batch_size, self.num_heads, seq_len_v, self.d_k)  \n",
    "        v = self.split_heads(self.w_v(input_V))  \n",
    "        output, attn_weights = Attention()(q, k, v, attn_mask)\n",
    "        # (batch_size, seq_len, self.d_model), (batch_size, self.num_heads, seq_len_q, seq_len_k)   \n",
    "        return output, attn_weights   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d69658b-03f3-400b-b1fa-440e31c8e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.6855,  0.5687],\n",
       "           [ 0.5009,  0.3546],\n",
       "           [ 0.6155,  0.4866]],\n",
       " \n",
       "          [[ 0.0450,  0.0735],\n",
       "           [-0.0086,  0.0953],\n",
       "           [ 0.0298,  0.0803]]],\n",
       " \n",
       " \n",
       "         [[[ 0.6620,  0.4569],\n",
       "           [ 0.5721,  0.4157],\n",
       "           [ 0.5411,  0.3756]],\n",
       " \n",
       "          [[ 0.0091,  0.1798],\n",
       "           [ 0.0060, -0.0081],\n",
       "           [ 0.0176,  0.0106]]]], grad_fn=<UnsafeViewBackward0>),\n",
       " tensor([[[[0.2473, 0.3629, 0.3898],\n",
       "           [0.6268, 0.1640, 0.2092],\n",
       "           [0.3813, 0.2811, 0.3377]],\n",
       " \n",
       "          [[0.5394, 0.2354, 0.2251],\n",
       "           [0.2666, 0.3013, 0.4321],\n",
       "           [0.4651, 0.2571, 0.2778]]],\n",
       " \n",
       " \n",
       "         [[[0.2934, 0.0974, 0.6092],\n",
       "           [0.3550, 0.4601, 0.1850],\n",
       "           [0.4028, 0.4481, 0.1492]],\n",
       " \n",
       "          [[0.1232, 0.8435, 0.0333],\n",
       "           [0.4097, 0.2247, 0.3656],\n",
       "           [0.4025, 0.3157, 0.2818]]]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head_attention = MultiHeadAttention(4, 2)\n",
    "multi_head_attention(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24780277-d0b4-4bf4-8f54-d7a5710e0bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
